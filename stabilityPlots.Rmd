---
output: html_document
---
# Simulating and Estimating CTRM processes

### Simulation

```{r init, cache=F, include=F}
require(stabledist)
require(fExtremes)
require(plyr)
# number of observations 
n = 100000
# tail parameter of waiting times
beta = 0.85
# scale parameter of waiting times
delta = n^(1/beta)
# shape parameter of GEV distribution
xi = 0.3
# times of events:
TT = cumsum(rstable(n,beta, 1, gamma=1, delta=0, pm=1))
# magnitudes of events (distribution irrelevant)
JJ = rgev(n, xi = xi, mu = 0, beta = 1) # don't know scaling!
JJ <- sapply(JJ, function(x) max(x, 0))
# consider the cutoff at the top epsMax values:
epsMax <- 0.10
# this cutoff translates to this many magnitudes:
m <- ceiling(epsMax * length(JJ))
idxJ <- order(JJ, decreasing = T)[1:m] 
```

We assume $N$ i.i.d. waiting times drawn from the positively skewed stable
distribution with stability parameter $\beta=`r beta`$, scaled with 
$N^{-1/\beta}$. This defines a renewal process, at whose renewal times we
assume i.i.d. magnitudes, drawn from a Generalized Extreme Value Distribution
with shape parameter $\xi = `r xi`$: 

```{r CTRM-plot, echo = F}
plot(TT,JJ, type = "h", main = "CTRM process", xlab = "time", ylab = "magnitude")
# lines(TT, cummax(JJ), col = 2)
```

Besides the magnitude of large events, their *timing* is of interest to us. 
We define the exceedance time of level $\ell \in [x_0,x_F]$ as
the random variable
\begin{align*}
T_\ell = \inf\{t: M(N(t)) > \ell\}
\end{align*}
and the exceedance as 
\begin{align*}
X_\ell = M(N(T_\ell)) - \ell.
\end{align*}

```{r exceedances, echo=F, fig.cap="Exceedance times (blue circles) and Exceedance sizes (red lines)."}
plot(TT,JJ, type = "h", main = "Exceedances", xlab = "time", ylab = "magnitude", col = "gray")
# Choose threshold ell so that there are k exceedances:
k = 10
ell <- (JJ[idxJ[k]] + JJ[idxJ[k+1]])/2
abline(h = ell, lty = 2)
lines(TT[idxJ[1:k]], rep(ell,k), type = "h", col = "gray")
points(TT[idxJ[1:k]], rep(0,k), col = 4, lwd = 4)
for(i in 1:10){
  lines(rep(TT[idxJ][i],2), c(JJ[idxJ][k], JJ[idxJ][i]), col = 2, lwd = 4) 
}
```

### Probability distribution of Exceedance Times

#### Result by Anderson (1987)

Anderson (1987) has shown that as $\ell \uparrow x_F$ 
(the right end-point of the distribution of magnitudes)
the following weak convergence holds: 

\begin{align}
\frac{T_\ell}{n(1/(1-F_J(\ell)))} \Rightarrow W_\beta.
\end{align}
Here, 

- $F_J(\cdot)$ is the CDF of the magnitudes $J_1, J_2, \ldots$
- $n(\cdot)$ is a norming function which varies regularly at $\infty$
  with parameter $1/\beta$
- $W_\beta$ is a Mittag-Leffler random variable, defined via its
  Laplace transform
  
\begin{align}
\newcommand{\ex}{\mathbf E}
\ex[\exp(-\lambda W_\beta)] = \frac{1}{1 + \lambda^\beta}.
\end{align}

More precisely, $n(t)$ is an asymptotic inverse to the function

\begin{align}
g(t) := 
\frac{t}{\Gamma(2-\beta) \int_0^t(1-F_W(u))\,du}
\in RV_\infty(\beta)
\end{align}

#### Approach in this paper

Meerschaert and Stoev (2008) have derived a scaling limit theorem for
the Continuous Time Random Maxima (CTRM) process
\begin{align}
M(t) = \bigvee_{k=1}^{N(t)} J_k
\end{align}
where $N(t)$ is the renewal process as above: Assume that

- $\left[ \bigvee_{k=1}^{\lfloor nt \rfloor} J_k - d(n)\right] / a(n) \Rightarrow A(t)$
- $b(n)^{-1}\sum_{k=1}^{\lfloor nt \rfloor} W_k \Rightarrow D(t)$

converge (weakly in Skorokhod space) for some norming sequences $a(n)$,
$d(n)$ and $b(n)$ which increase as $n \to \infty$. Then 

\begin{align}
\frac{M(ct) - d(\tilde b(c))}{a(\tilde b(c))}
\Rightarrow
A(E(t)), \quad c \to \infty
\end{align}

where 
$\tilde b(c)$ is asymptotically inverse to $b(n)$ and
$E(t) = \inf\{r: D(r) > t\}$ is the stochastic process inverse to $D(t)$.

For "large" $c$ and for $t$ comparable to $c$, we may hence approximate 

\begin{align}
M(t) \approx a(\tilde b(c)) A(E(t/c)) + d(\tilde b(c)). 
\end{align}

Recalling that $c \sim b(\tilde b(c))$, we set $n = \tilde b(c)$
to get

\begin{align}
M(t) \approx a(n) A(E(t/b(n))) + d(n). 
\end{align}

Then we have 

\begin{align}
T_\ell > t \Longleftrightarrow M(t) \le \ell
\stackrel{\approx}{\Longleftrightarrow}
A(E(t/b(n))) \le \frac{\ell - d(n)}{a(n)} =: \ell^*
\\
\Longleftrightarrow
\xi_{\ell^*} > t/b(n)
\Longleftrightarrow
b(n) \xi_{\ell^*} > t
\end{align}

where $\xi_a := \inf\{t: A(E(t)) > a\}$ is the hitting time of level
$a$ by the process $A(E(t))$. Hence we may approximate the distribution
of $T_\ell$ by the distribution of the random variable $\xi_{\ell^*}$, rescaled
with $b(n)$.  It was shown by Meerschaert & Stoev (2008) that 

$$\xi_a \stackrel{d}{=} (-\log F_A(a))^{-1/\beta} W_\beta$$

where $F_A(\cdot)$ is the CDF of $A:= A(1)$. Summing up, the exceedance
time $T_\ell$ is asymptotically Mittag-Leffler distributed
as the threshold $\ell$ approaches the right end $x_*$ of the distribution
of $J$:

\begin{align}
T_\ell \stackrel{a}{\sim} {\rm ML}\left(\beta, b(n) [-\log F_A(\ell^*)]^{-1/\beta}\right)
\end{align}



## Estimation

Note that $N$ is the total number of observations, whereas $n$ is the number
of observations used in the approximation

$$A \approx \frac{\bigvee_{k=1}^n J_k - d(n)}{a(n)}.$$

Roughly speaking, the set of all $N$ observations is divided at the
exceedance times into smaller blocks of size $\approx n$. 
(Is that right?) Since

\begin{align}
\bigvee_{k=1}^n J_k \le \ell \stackrel{\approx}{\Longleftrightarrow}
A \le \ell^*,
\end{align}
we have 
\begin{align}
-\log F_A(\ell^*) 
\approx -n \log F_J(\ell)
\approx -n \log \hat F_J(\ell)
\approx n (1- \hat F_J(\ell))
\approx n \#\{k: J_k > \ell\} / N,
\end{align}
where the empirical CDF of $J$ is 
$$\hat F_J(\ell) := \#\{k: J_k \le \ell\}/N.$$

Assume now a time series of magnitudes, and that interest lies in the
estimation of the timings of the large magnitudes.
Consider a minimum threshold $\ell_{min}$, e.g. at the $`r 1- epsMax`$ quantile
of the empirical distribution of $J$.
Vary the threshold $\ell$ on the interval $[\ell_{min}, \ell_{max}]$, and consider
the resulting sequences of exceedance sizes and exceedance times 
$\{(X_{\ell,i}, T_{\ell,i})\}$. 
Due to the renewal property, this sequence is i.i.d., and 
$T_{\ell,1}, T_{\ell,2}, \ldots$ can be modelled by a Mittag-Leffler
distribution. We use the method of log-moments estimator, taken from 
Cahoy (2012), which provides a point-estimate and an asymptotically normal
confidence interval, at default confidence level 95%. 


```{r tail-plot, cache=T, echo=F, warning=F, fig.cap="Estimate of tail parameter of Mittag Leffler distribution (y-axis), for observations thresholded at the top k observations (x-axis). The dotted line represents the correct value."}
source("MittagLefflerEstimation.R")
# extracts (preceding) durations of the m largest exceedances
Tell <- function(TT,idxJ,m){
  m=ceiling(m)
  thinT <- sort(TT[idxJ[1:m]])
  diff(c(0,thinT))
}
# creates a dataframe with point estimates and confidence intervals
# of the Mittag-Leffler parameters mu and nu:
estimates <- ldply(.data = 10:m, function(k){
  est <- ml.par.est(Tell(TT,idxJ,k),0.05)
  return(c(est$nu, est$CInu, est$mu, est$CImu, k))
})
# beta = shape; sigma = scale; topk = number of values used in estimate
names(estimates) <- c("beta","betaL","betaH","mu","muL","muH","topk")
# plot estimates of tail parameter beta
plot(estimates$topk,estimates$beta, type="l",ylab= "beta", xlab = "k", 
     xlim=c(0,m), ylim = c(0,1), main="tail parameter")
lines(estimates$topk,estimates$betaH, type="l", lty =2)
lines(estimates$topk,estimates$betaL, type="l", lty =2)
abline(h = beta, lty = 3)
```

Recall that the scale parameter of the Mittag-Leffler distribution satisfies
asymptotically

$$\delta = b(n)[-\log F_A(\ell^*)]^{-1/\beta}
= \frac{b(n)}{n^{1/\beta}} [- \log F_J(\ell)]^{-1/\beta}.$$





depends on the threshold $\ell^*$ as well as on the tail parameter $\beta$, 
we plot the estimate of $b(n)$
\begin{align}
b(n) = \delta \times (-\log(1-\varepsilon(\ell^*)))^{1/\beta}
\end{align}
with an estimate for $\beta$ plugged in from the previous step. 

```{r scale-plot, cache=F, echo=F, warning=F, fig.cap="Estimate of scale parameter of Mittag Leffler distribution (y-axis), for observations thresholded at the top k observations (x-axis). The dotted line represents the true scaling parameter."}
# extract scale from parametrization
estimates$delta <- estimates$mu^{-1/estimates$beta}
# eps := fraction of magnitudes above threshold
estimates$eps <- estimates$topk / n 
# plot with known beta:
# plot(estimates$topk, estimates$delta * (-log(1-estimates$eps))^(1/beta), type="l", xlab = "k", ylab = "delta (beta known)", main="scale parameter")
# plot with estimated beta:
plot(estimates$topk, estimates$delta * (-log(1-estimates$eps))^(1/estimates$beta), type="l", ylim=c(0,2*delta), xlab = "k", ylab = "delta (beta unknown)", main="scale parameter")
abline(h = delta, lty = 3)
```



